<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>爬取拉钩python数据分析职位招聘信息 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="python数据分析python数据分析是目前python最火的方向之一，为了解目前市场对该职位的需求，我们爬取了拉钩上对pythons数据分析的招聘信息。">
<meta property="og:type" content="article">
<meta property="og:title" content="爬取拉钩python数据分析职位招聘信息">
<meta property="og:url" content="http://yoursite.com/2020/03/15/python%E7%88%AC%E5%8F%96%E6%8B%89%E9%92%A9python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%81%8C%E4%BD%8D%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="python数据分析python数据分析是目前python最火的方向之一，为了解目前市场对该职位的需求，我们爬取了拉钩上对pythons数据分析的招聘信息。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci8yLnBuZw?x-oss-process=image/format,png">
<meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci80LnBuZw?x-oss-process=image/format,png">
<meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci81LnBuZw?x-oss-process=image/format,png">
<meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci8xMC5wbmc?x-oss-process=image/format,png">
<meta property="article:published_time" content="2020-03-15T08:55:23.000Z">
<meta property="article:modified_time" content="2020-03-15T09:17:44.657Z">
<meta property="article:author" content="huihui">
<meta property="article:tag" content="Technology Blog">
<meta property="article:tag" content="Python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci8yLnBuZw?x-oss-process=image/format,png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-python爬取拉钩python数据分析职位招聘信息" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2020/03/15/python%E7%88%AC%E5%8F%96%E6%8B%89%E9%92%A9python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%81%8C%E4%BD%8D%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF/" class="article-date">
  <time datetime="2020-03-15T08:55:23.000Z" itemprop="datePublished">2020-03-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      爬取拉钩python数据分析职位招聘信息
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="python数据分析"><a href="#python数据分析" class="headerlink" title="python数据分析"></a>python数据分析</h2><p>python数据分析是目前python最火的方向之一，为了解目前市场对该职位的需求，我们爬取了拉钩上对pythons数据分析的招聘信息。</p>
<a id="more"></a>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><blockquote>
<p>系统：windows7</p>
</blockquote>
<blockquote>
<p>python版本：3.7.1</p>
</blockquote>
<h2 id="爬虫分析"><a href="#爬虫分析" class="headerlink" title="爬虫分析"></a>爬虫分析</h2><p>1.谷歌浏览器打开拉钩官网<a href="https://www.lagou.com/，搜索框中输入要查询的职位，右键点击检查，找到名为position" target="_blank" rel="noopener">https://www.lagou.com/，搜索框中输入要查询的职位，右键点击检查，找到名为position</a><br>Ajax.json?needAddtionalResult=false的链接，这就是我们要重点分析的地方。</p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-aVlroUi4-1584262486496)(<a href="https://raw.githubusercontent.com/xiaohui96/picture/master/1.png)]" target="_blank" rel="noopener">https://raw.githubusercontent.com/xiaohui96/picture/master/1.png)]</a><br>抱着侥幸心理我们将链接<a href="https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false输入浏览器中，" target="_blank" rel="noopener">https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false输入浏览器中，</a><br>发现提示：{“status”:false,”msg”:”您操作太频繁,请稍后再访问”,”clientIp”:”113.57.183.6”,”state”:2402}<br>可见想要获取信息不是那么简单。</p>
<p>2.分析报文<br>首先发送get请求，获取session</p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-MAiZsAyb-1584262486497)(<a href="https://raw.githubusercontent.com/xiaohui96/picture/master/7.png)]" target="_blank" rel="noopener">https://raw.githubusercontent.com/xiaohui96/picture/master/7.png)]</a></p>
<p>session更新，发送post请求</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci8yLnBuZw?x-oss-process=image/format,png" alt="图片"></p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-7QQkdHoM-1584262486501)(<a href="https://raw.githubusercontent.com/xiaohui96/picture/master/3.png)]" target="_blank" rel="noopener">https://raw.githubusercontent.com/xiaohui96/picture/master/3.png)]</a><br>比较发现get请求和pos请求参数一致，这无疑减少了我们的工作量</p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-VdZqjII6-1584262486503)(<a href="https://raw.githubusercontent.com/xiaohui96/picture/master/8.png)]" target="_blank" rel="noopener">https://raw.githubusercontent.com/xiaohui96/picture/master/8.png)]</a></p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-I21jVa7l-1584262486504)(<a href="https://raw.githubusercontent.com/xiaohui96/picture/master/9.png)]" target="_blank" rel="noopener">https://raw.githubusercontent.com/xiaohui96/picture/master/9.png)]</a></p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci80LnBuZw?x-oss-process=image/format,png" alt="图片"><br>分析翻页，点击下一页则会新增一天get请求，并且Form Data中的pn则会加1，这是翻页的关键</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci81LnBuZw?x-oss-process=image/format,png" alt="图片"></p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-pptqy4qa-1584262486507)(<a href="https://raw.githubusercontent.com/xiaohui96/picture/master/6.png)]" target="_blank" rel="noopener">https://raw.githubusercontent.com/xiaohui96/picture/master/6.png)]</a><br>分析数据结构，选择需要存储的信息</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci8xMC5wbmc?x-oss-process=image/format,png" alt="图片"></p>
<p>分析完报文后就理清了我们的爬虫思路，首先构造get请求获取session;；更新session，发送post请求；通过改变Form Data中的pn值<br>实现翻页循环；获取并存储数据</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>1.构造get请求</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def get_json(url, data):</span><br><span class="line">    # 构造随机请求头</span><br><span class="line">    for i in range(100):</span><br><span class="line">        ua &#x3D; UserAgent()</span><br><span class="line">        # print(ua.random)</span><br><span class="line"></span><br><span class="line">    my_headers &#x3D; &#123;</span><br><span class="line">        # &quot;User-Agent&quot;: &quot;Mozilla&#x2F;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) &quot;</span><br><span class="line">        # &quot;Chrome&#x2F;67.0.3396.99 Safari&#x2F;537.36&quot;,</span><br><span class="line">        &quot;User-Agent&quot;: &quot;ua.random&quot;,</span><br><span class="line">        &quot;Referer&quot;: &quot;https:&#x2F;&#x2F;www.lagou.com&#x2F;jobs&#x2F;list_python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90&quot;</span><br><span class="line">                   &quot;?city&#x3D;%E5%85%A8%E5%9B%BD&amp;cl&#x3D;false&amp;fromSearch&#x3D;true&amp;labelWords&#x3D;&amp;suginput&#x3D;&quot;,</span><br><span class="line">        &quot;Content-Type&quot;: &quot;application&#x2F;json;charset&#x3D;UTF-8&quot;&#125;</span><br></pre></td></tr></table></figure>
<p>get请求主要由User_Agent, Referer和Content-Type组成，其中后两者可从上文报文中获取，为减少爬虫次数过多而被封，我们可通过<br>UserAgent构造随机请求头。UserAgent可通过pip install fake_useragent获得。下图是随机生成的请求头。</p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-xDkr5qVQ-1584262486509)(<a href="https://raw.githubusercontent.com/xiaohui96/picture/master/11.png)]" target="_blank" rel="noopener">https://raw.githubusercontent.com/xiaohui96/picture/master/11.png)]</a></p>
<p>2.获取并更新session，发送post请求</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 获取session</span><br><span class="line">   session &#x3D; requests.session()</span><br><span class="line">   # 更新</span><br><span class="line">   session.headers.update(my_headers)</span><br><span class="line">   session.get(</span><br><span class="line">       &quot;https:&#x2F;&#x2F;www.lagou.com&#x2F;jobs&#x2F;list_python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90&quot;</span><br><span class="line">       &quot;?city&#x3D;%E5%85%A8%E5%9B%BD&amp;cl&#x3D;false&amp;fromSearch&#x3D;true&amp;labelWords&#x3D;&amp;suginput&#x3D;&quot;)</span><br><span class="line">   content &#x3D; session.post(url&#x3D;url, data&#x3D;data)</span><br></pre></td></tr></table></figure>
<p>3.构造翻页</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for num in range(1, page + 1):</span><br><span class="line">    url &#x3D; &#39;https:&#x2F;&#x2F;www.lagou.com&#x2F;jobs&#x2F;positionAjax.json?needAddtionalResult&#x3D;false&#39;</span><br><span class="line">    data &#x3D; &#123;</span><br><span class="line">        &#39;first&#39;: &#39;false&#39;,</span><br><span class="line">        &#39;pg&#39;: num,</span><br><span class="line">        &#39;kd&#39;: &#39;python数据分析&#39;,</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>4.存储数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 创建workbook,即excel</span><br><span class="line">        workbook &#x3D; xlwt.Workbook(encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">        # 创建表,第二参数用于确认同一个cell单元是否可以重设值</span><br><span class="line">        worksheet &#x3D; workbook.add_sheet(&#39;python数据分析&#39;, cell_overwrite_ok&#x3D;True)</span><br><span class="line">        for i, row in enumerate(info_result):</span><br><span class="line">            # print(row)</span><br><span class="line">            for j, col in enumerate(row):</span><br><span class="line">                # print(col)</span><br><span class="line">                worksheet.write(i, j, col)</span><br><span class="line">        workbook.save(&#39;python数据分析.xls&#39;)</span><br></pre></td></tr></table></figure>
<p>以上就是爬虫总体代码思路，完整代码如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;env python</span><br><span class="line"># encoding: utf-8</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@author: xiaohui</span><br><span class="line">@contact: xiaohui1295371450@163.com</span><br><span class="line">@file: crawl.py</span><br><span class="line">@time: 2019-05-14 10:44</span><br><span class="line">@desc: crawl data on lagou</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import json</span><br><span class="line">import requests</span><br><span class="line">import xlwt</span><br><span class="line">import time</span><br><span class="line">from fake_useragent import UserAgent</span><br><span class="line"></span><br><span class="line"># 获取存储职位信息的json对象，遍历获得城市、公司名称、工作地点、学历要求、职位名称、薪资、工作年限</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_json(url, data):</span><br><span class="line">    # 构造随机请求头</span><br><span class="line">    for i in range(100):</span><br><span class="line">        ua &#x3D; UserAgent()</span><br><span class="line">        print(ua.random)</span><br><span class="line"></span><br><span class="line">    my_headers &#x3D; &#123;</span><br><span class="line">        # &quot;User-Agent&quot;: &quot;Mozilla&#x2F;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) &quot;</span><br><span class="line">        # &quot;Chrome&#x2F;67.0.3396.99 Safari&#x2F;537.36&quot;,</span><br><span class="line">        &quot;User-Agent&quot;: &quot;ua.random&quot;,</span><br><span class="line">        &quot;Referer&quot;: &quot;https:&#x2F;&#x2F;www.lagou.com&#x2F;jobs&#x2F;list_python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90&quot;</span><br><span class="line">                   &quot;?city&#x3D;%E5%85%A8%E5%9B%BD&amp;cl&#x3D;false&amp;fromSearch&#x3D;true&amp;labelWords&#x3D;&amp;suginput&#x3D;&quot;,</span><br><span class="line">        &quot;Content-Type&quot;: &quot;application&#x2F;json;charset&#x3D;UTF-8&quot;&#125;</span><br><span class="line">    time.sleep(5)</span><br><span class="line">    # 获取session</span><br><span class="line">    session &#x3D; requests.session()</span><br><span class="line">    # 更新</span><br><span class="line">    session.headers.update(my_headers)</span><br><span class="line">    session.get(</span><br><span class="line">        &quot;https:&#x2F;&#x2F;www.lagou.com&#x2F;jobs&#x2F;list_python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90&quot;</span><br><span class="line">        &quot;?city&#x3D;%E5%85%A8%E5%9B%BD&amp;cl&#x3D;false&amp;fromSearch&#x3D;true&amp;labelWords&#x3D;&amp;suginput&#x3D;&quot;)</span><br><span class="line">    content &#x3D; session.post(url&#x3D;url, data&#x3D;data)</span><br><span class="line">    result &#x3D; content.json()</span><br><span class="line">    info &#x3D; result[&#39;content&#39;][&#39;positionResult&#39;][&#39;result&#39;]</span><br><span class="line">    info_list &#x3D; []</span><br><span class="line">    information &#x3D; []</span><br><span class="line">    for job in info:</span><br><span class="line">        # 城市</span><br><span class="line">        information.append(job[&#39;city&#39;])</span><br><span class="line">        # 公司全名</span><br><span class="line">        information.append(job[&#39;companyFullName&#39;])</span><br><span class="line">        # 工作地点</span><br><span class="line">        information.append(job[&#39;district&#39;])</span><br><span class="line">        # 学历要求</span><br><span class="line">        information.append(job[&#39;education&#39;])</span><br><span class="line">        # 职位名称</span><br><span class="line">        information.append(job[&#39;positionName&#39;])</span><br><span class="line">        # 薪资</span><br><span class="line">        information.append(job[&#39;salary&#39;])</span><br><span class="line">        # 工作年限</span><br><span class="line">        information.append(job[&#39;workYear&#39;])</span><br><span class="line">        info_list.append(information)</span><br><span class="line">    return info_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    page &#x3D; int(input(&#39;输入爬取的页码总数：&#39;))</span><br><span class="line">    info_result &#x3D; []</span><br><span class="line">    title &#x3D; [&#39;城市&#39;, &#39;公司全名&#39;, &#39;工作地点&#39;, &#39;学历要求&#39;, &#39;职位名称&#39;, &#39;薪资&#39;, &#39;工作年限&#39;]</span><br><span class="line">    info_result.append(title)</span><br><span class="line">    for num in range(1, page + 1):</span><br><span class="line">        url &#x3D; &#39;https:&#x2F;&#x2F;www.lagou.com&#x2F;jobs&#x2F;positionAjax.json?needAddtionalResult&#x3D;false&#39;</span><br><span class="line">        data &#x3D; &#123;</span><br><span class="line">            &#39;first&#39;: &#39;false&#39;,</span><br><span class="line">            &#39;pg&#39;: num,</span><br><span class="line">            &#39;kd&#39;: &#39;python数据分析&#39;,</span><br><span class="line">        &#125;</span><br><span class="line">        try:</span><br><span class="line">            info &#x3D; get_json(url, data)</span><br><span class="line">            info_result &#x3D; info_result + info</span><br><span class="line">            print(&quot;第%s页爬取成功&quot; % num)</span><br><span class="line">        except Exception as msg:</span><br><span class="line">            print(&quot;第%s页爬取失败&quot; % num)</span><br><span class="line"></span><br><span class="line">        # 创建workbook,即excel</span><br><span class="line">        workbook &#x3D; xlwt.Workbook(encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">        # 创建表,第二参数用于确认同一个cell单元是否可以重设值</span><br><span class="line">        worksheet &#x3D; workbook.add_sheet(&#39;python数据分析&#39;, cell_overwrite_ok&#x3D;True)</span><br><span class="line">        for i, row in enumerate(info_result):</span><br><span class="line">            # print(row)</span><br><span class="line">            for j, col in enumerate(row):</span><br><span class="line">                # print(col)</span><br><span class="line">                worksheet.write(i, j, col)</span><br><span class="line">        workbook.save(&#39;python数据分析.xls&#39;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>分析我们获得的excel数据，主要招聘地依旧集中在北京、上海和广州，薪资集中在15k-30k之间，可以说情景不错。<br>这不失为度过目前互联网寒冬的一种选择。</p>
<p>附：<a href="https://pan.baidu.com/s/1q8kSg1tvubtLfSK-X525Cg" target="_blank" rel="noopener">完整代码和爬虫数据结果</a><br>提取码：n9d9</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/03/15/python%E7%88%AC%E5%8F%96%E6%8B%89%E9%92%A9python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%81%8C%E4%BD%8D%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF/" data-id="ck7svpm9b000jm0cp2ddlfa3m" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Technology-Blog/" rel="tag">Technology Blog</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/03/15/Linux%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85python3-x/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Linux环境下安装python3.x
        
      </div>
    </a>
  
  
    <a href="/2020/03/15/Linux%E4%B8%8Btar%E8%A7%A3%E5%8E%8B%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8Fbug/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Linux下tar解压文件的一个小bug</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python3-x/" rel="tag">Python3-x</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Technology-Blog/" rel="tag">Technology Blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/life/" rel="tag">life</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Python3-x/" style="font-size: 10px;">Python3-x</a> <a href="/tags/Technology-Blog/" style="font-size: 20px;">Technology Blog</a> <a href="/tags/life/" style="font-size: 10px;">life</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/03/15/beautiful-sentences/">beautiful sentences</a>
          </li>
        
          <li>
            <a href="/2020/03/15/Linux%E7%B3%BB%E7%BB%9F%E6%9B%B4%E6%8D%A2yum%E6%BA%90/">Linux系统更换yum源</a>
          </li>
        
          <li>
            <a href="/2020/03/15/Linux%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85python3-x/">Linux环境下安装python3.x</a>
          </li>
        
          <li>
            <a href="/2020/03/15/python%E7%88%AC%E5%8F%96%E6%8B%89%E9%92%A9python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%81%8C%E4%BD%8D%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF/">爬取拉钩python数据分析职位招聘信息</a>
          </li>
        
          <li>
            <a href="/2020/03/15/Linux%E4%B8%8Btar%E8%A7%A3%E5%8E%8B%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8Fbug/">Linux下tar解压文件的一个小bug</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 huihui<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>