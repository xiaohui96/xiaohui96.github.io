<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>数据挖掘导论—第四章分类（1）</title>
    <url>/2020/04/12/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA%E2%80%94%E7%AC%AC%E5%9B%9B%E7%AB%A0%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<html><head><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
</head><body><p>4.1 预备知识</p>
<ul>
<li><p>分类任务的输入数据是记录的集合。</p>
<a id="more"></a></li>
<li><p>每条记录也称实例或样例，用元祖(x,y)表示，其中x是属性的集合，而y是一个特殊的属性，指出样例的类标号。</p>
</li>
<li><p>类标号必须是离散属性，这正是区别分类与回归的关键特征。回归是一种预测建模模型，其中目标属性y是连续的。</p>
</li>
<li><p>分类任务就是通过学习得到一个目标函数f，把每个属性集x映射到一个预先定义的类标号y。</p>
</li>
<li><p>分类技术非常适合预测或描述二元或标称类型的数据集，对于序数分类（例如，把人分类为高收入、中等收入或低收入者），分类技术不太有效，因为分类技术不考虑隐含在目标类中的序关系。</p>
</li>
</ul>
<p>4.2 解决分类问题的一般方法</p>
<ul>
<li><p>分类法的例子包括决策树分类法、基于规则的分类法、神经网络、支持向量机和朴素贝叶斯分类法。</p>
</li>
<li><p>分类模型的性能根据模型准确和错误预测的检验记录计数进行评估，这些计数存放在称作为混淆矩阵（confusion<br>matrix）的表格中。下表为二类问题的混淆矩阵，表中每个表项$$f_{i j}$$表示实际类标号为i但被预测为类j的记录数。</p>
</li>
</ul>
<p><img alt="图片" data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci9jb25mdXNpb24tbWF0cml4LnBuZw?x-oss-process=image/format,png"></p>
<p>准确率=$$\frac{f_{11}+f_{00}}{f_{10}+f_{11}+f_{01}+f_{00}}$$</p>
</body></html>]]></content>
      <tags>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep Learning</title>
    <url>/2020/04/09/Deep-Learning/</url>
    <content><![CDATA[<html><head><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

</head><body><p>业内有个形象的比喻来形容深度学习：拿来药材（数据）、架起八卦炉（模型）、点着六味真火（优化算法），就摇着蒲扇等着丹药出炉了。</p>
<a id="more"></a>
<p>说到深度学习优化算法，入门级必从SGD学起，老司机则会告诉你更好的还有AdaGrad /<br>AdaDelta，或者直接无脑用Adam。可是看看学术界的最新paper，却发现一众大神还在用着入门级的SGD，最多加个Moment或者Nesterov ，还经常会黑一下Adam。</p>
<p>深度学习优化算法经历了SGD→SGDM→NAG→AdaGrad→AdaDelta→Adam→Nadam这样的发展历程。Google一下就可以看到很多的教程文章，详细告诉你这些算法是如何一步一步演变而来的。在这里，我们换一个思路，用一个框架来梳理所有的优化算法，做一个更加高屋建瓴的对比。</p>
<p>1.一个框架回顾优化算法</p>
<p>1.1 优化算法通用框架<br>首先定义：待优化参数：w，目标函数：f(w)，初始学习率 ：α。而后开始迭代优化，在每个epoch中：</p>
<ul>
<li>计算目标函数关于当前参数的梯度：$$g_{t}=\nabla f\left(w_{t}\right)$$</li>
<li>根据历史梯度计算一阶动量和二阶动量：<br>$$\begin{aligned}<br>&m_{t}=\phi\left(g_{1}, g_{2}, \cdots, g_{t}\right)\<br>&V_{t}=\psi\left(g_{1}, g_{2}, \cdots, g_{t}\right)<br>\end{aligned}$$</li>
<li>计算当前时刻的下降梯度：$$\eta_{t}=\alpha \cdot m_{t} / \sqrt{V_{t}}$$</li>
<li>根据下降梯度进行更新：$$w_{t+1}=w_{t}-\eta_{t}$$</li>
</ul>
<p>掌握了掌握了这个框架，就可以轻松设计自己的优化算法。步骤3、4对于各个算法都是一致的，主要差别体现在1和2上。</p>
<p>2.固定学习率的优化算法</p>
<p>2.1 SGD</p>
<p>SGD没有动量的概念，也就是说：$$m_{t}=g_{t} ; V_{t}=I^{2}$$<br>带入步骤3，可以看到下降梯度就是最简单的：$$\eta_{t}=\boldsymbol{\alpha} \cdot g_{t}$$<br>SGD最大的缺点是下降速度慢，而且可能会在沟壑的两边持续震荡，停留在一个局部最优点。</p>
<p>2.2 SGD with Momentum</p>
<p>为了抑制SGD的动荡，SGDM认为梯度下降过程可以加入惯性。下坡的时候，如果发现是陡坡，那就利用惯性跑的快一点。SGDM全称是SGD with momentum，在SGD基础上引入了一阶动量：<br>$$m_{t}=\beta_{1} \cdot m_{t-1}+\left(1-\beta_{1}\right) \cdot g_{t}$$<br>一阶动量是各个时刻梯度方向上的指数移动平均值，约等于最近$$1 /(1-\beta 1)$$个时刻的梯度向量和的平均值。也就是说，t时刻的下降方向，不仅由当前的梯度方向决定，而且由此前累积的下降方向决定。β1的经验至为0.9，这就意味着下降方向主要是此前累积的下降方向，并略微偏向当前时刻的下降方向。想象高速公路上汽车转弯，在高速向前的同时略微偏向，急转弯可是要出事的。</p>
<p>2.3 SGD with Nesterov Acceleration<br>SGD还有一个问题就是困在局部最优的沟壑里面震荡。想象一下你走到一个盆地，四周都是略高的小山，你觉得没有下坡的方向，那就只能待在这里了。可是如果你爬上高地，就会发现外面的世界还很广阔。因此，我们不能停留在当前位置去观察未来的方向，而要向前一步、多看一步、看远一些。</p>
<p><img alt="SGDN" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/SGDN.png"></p>
<p>NAG全称Nesterov  Accelerated Gradient，是在SGD、SGD-M的基础上的进一步改进，改进点在于步骤1。我们知道在时刻t的主要下降方向是由累积动量决定的，自己的梯度方向说了也不算，那与其看当前梯度方向，不如先看看如果跟着累积动量走了一步，那个时候再怎么走。因此，NAG在步骤1，不计算当前位置的梯度方向，而是计算如果按照累积动量走了一步，那个时候的下降方向：<br>$$g_{t}=\nabla f\left(w_{t}-\alpha \cdot m_{t-1} / \sqrt{V_{t-1}}\right)$$，然后用下一个点的梯度方向，与历史累积动量相结合，计算步骤2中当前时刻的累积动量。</p>
<p>3.自适应学习率的优化算法</p>
<p>此前我们都没有用到二阶动量。二阶动量的出现，才意味着“自适应学习率”优化算法时代的到来。SGD及其变种以同样的学习率更新每个参数，但深度神经网络往往包含大量的参数，这些参数并不是总会用得到（想想大规模的embedding）。对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些。</p>
<p>3.1 AdaGrad</p>
<p>怎么样去度量历史更新频率呢？那就是二阶动量——该维度上，迄今为止所有梯度值的平方和：<br>$$V_{t}=\sum_{\tau=1}^{t} g_{\tau}^{2}$$步骤3中的下降梯度：$$\eta_{t}=\alpha \cdot m_{t} / \sqrt{V_{t}}$$<br>可以看出，此时实质上的学习率由变成了$$\alpha$$变成了$$\alpha / \sqrt{V_{t}}$$。一般为了避免分母为0， 会在分母上加一个小的平滑项。因此$$\sqrt{V_{t}}$$是恒大于0的，而且参数更新越频繁，二阶动量越大，学习率就越小。这一方法在稀疏数据场景下表现非常好。但也存在一些问题：因为是单调递增的，会使学习率单调递减至0，可能会使得训练过程提前结束，及时后续还有数据也无法学到必要的知识。</p>
<p>3.2 AdaDelta/RMSProp</p>
<p>由于AdaGrad单调递减的学习率变化过于激进，我们考虑一个改变二阶动量计算方法的策略：不累积全部历史梯度，而只关注过去一段时间窗口的下降梯度。这也就是AdaDelta<br>名称中Delta的来历。修改的思路很简单。前面我们讲到，指数移动平均值大约就是过去一段时间的平均值，因此我们用这一方法来计算二阶累积动量：$$V_{t}=\beta_{2} * V_{t-1}+\left(1-\beta_{2}\right) g_{t}^{2}$$就避免了二阶动量持续累积、导致训练过程提前结束的问题了。  </p>
<p>3.3 Adam </p>
<p>谈到这里，Adam和Nadam的出现就很自然而然了——它们是前述方法的集大成者。我们看到，SGD-M在SGD基础上增加了一阶动量，AdaGrad<br>和AdaDelta在SGD基础上增加了二阶动量。把一阶动量和二阶动量都用起来，就是Adam了——Adaptive + Momentum。<br>SGD的一阶动量：$$m_{t}=\beta_{1} \cdot m_{t-1}+\left(1-\beta_{1}\right) \cdot<br>g_{t}$$<br>加上AdaDelta的二阶动量：$$V_{t}=\beta_{2} * V_{t-1}+\left(1-\beta_{2}\right)<br>g_{t}^{2}$$<br>优化算法里最常见的两个超参数$$\beta_{1}, \beta_{2}$$，都在这里了，前者控制一阶动量，后者控制二阶动量。                                                         </p>
<p>3.4 Nadam</p>
<p>最后是Nadam。我们说Adam是集大成者，但它居然遗漏了Nesterov，这还能忍？必须给它加上，按照NAG的步骤1：$$g_{t}=\nabla f\left(w_{t}-\alpha \cdot m_{t-1} / \sqrt{V_{t}}\right)$$<br>就是Nesterov + Adam = Nadam了。说到这里，大概可以理解为什么j经常有人说 Adam / Nadam 目前最主流、最好用的优化算法了。新手上路，先拿来一试，收敛速度嗖嗖滴，效果也是杠杠滴             </p>
<p>4.Adam：可能不收敛   </p>
<p>这篇是正在深度学习领域顶级会议之一 ICLR 2018 匿名审稿中的一篇论文《On the Convergence of Adam and Beyond》，探讨了Adam算法的收敛性，通过反例证明了Adam在某些情况下可能会不收敛。<br>回忆一下上文提到的各大优化算法的学习率：$$\eta_{t}=\alpha / \sqrt{V_{t}}$$<br>其中，SGD没有用到二阶动量，因此学习率是恒定的（实际使用过程中会采用学习率衰减策略，因此学习率递减）。AdaGrad的二阶动量不断累积，单调递增，因此学习率是单调递减的。因此，这两类算法会使得学习率不断递减，最终收敛到0，模型也得以收敛。<br>但AdaDelta和Adam则不然。二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得可能会时大时小，不是单调变化。这就可能在训练后期引起学习率的震荡，导致模型无法收敛。<br>这篇文章也给出了一个修正的方法。由于Adam中的学习率主要是由二阶动量控制的，为了保证算法的收敛，可以对二阶动量的变化进行控制，避免上下波动。 $$V_{t}=\max \left(\beta_{2} * V_{t-1}+\left(1-\beta_{2}\right) g_{t}^{2}, V_{t-1}\right)$$<br>通过这样修改，就保证了$$\left|V_{t}\right| \geq\left|V_{t-1}\right|$$从而使得学习率单调递减。</p>
<p>5.Adam: 可能错过全局最优解</p>
<p>深度神经网络往往包含大量的参数，在这样一个维度极高的空间内，非凸的目标函数往往起起伏伏，拥有无数个高地和洼地。有的是高峰，通过引入动量可能很容易越过；但有些是高原，可能探索很多次都出不来，于是停止了训练。<br>近期Arxiv上的两篇文章谈到这个问题。第一篇就是前文提到的吐槽Adam最狠的UC Berkeley的文章《The Marginal Value of Adaptive Gradient Methods in Machine Learning》。文中说到，同样的一个优化问题，不同的优化算法可能会找到不同的答案，但自适应学习率的算法往往找到非常差的答案（very poor solution）。他们设计了一个特定的数据例子，自适应学习率算法可能会对前期出现的特征过拟合，后期才出现的特征很难纠正前期的拟合效果。但这个文章给的例子很极端，在实际情况中未必会出现。<br>另外一篇是《Improving Generalization Performance by Switching from Adam to SGD》，进行了实验验证。他们CIFAR-10数据集上进行测试，Adam的收敛速度比SGD要快，但最终收敛的结果并没有SGD好。他们进一步实验发现，主要是后期Adam的学习率太低，影响了有效的收敛。他们试着对Adam的学习率的下界进行控制，发现效果好了很多。<br>于是他们提出了一个用来改进Adam的方法：前期用Adam，享受Adam快速收敛的优势；后期切换到SGD，慢慢寻找最优解。这一方法以前也被研究者们用到，不过主要是根据经验来选择切换的时机和切换后的学习率。这篇文章把这一切换过程傻瓜化，给出了切换SGD的时机选择方法，以及学习率的计算方法，效果看起来也不错。<br>这个算法挺有趣，这里先贴个算法框架图：</p>
<p><img alt="SWATS" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/SWATS.png"></p>
<p>6.到底用Adam还是SGD</p>
<p>所以，谈到现在，到底Adam好还是SGD好？这可能是很难一句话说清楚的事情。去看学术会议中的各种paper，用SGD的很多，Adam的也不少，还有很多偏爱AdaGrad或者AdaDelta。可能研究员把每个算法都试了一遍，哪个出来的效果好就用哪个了。毕竟paper的重点是突出自己某方面的贡献，其他方面当然是无所不用其极，怎么能输在细节上呢？<br>而从这几篇怒怼Adam的paper来看，多数都构造了一些比较极端的例子来演示了Adam失效的可能性。这些例子一般过于极端，实际情况中可能未必会这样，但这提醒了我们，理解数据对于设计算法的必要性。优化算法的演变历史，都是基于对数据的某种假设而进行的优化，那么某种算法是否有效，就要看你的数据是否符合该算法的胃口了。<br>算法固然美好，数据才是根本。<br>另一方面，Adam之流虽然说已经简化了调参，但是并没有一劳永逸地解决问题，默认的参数虽然好，但也不是放之四海而皆准。因此，在充分理解数据的基础上，依然需要根据数据特性、算法特性进行充分的调参实验。</p>
<p>7.不同算法分核心差异</p>
<p>从第一篇的框架中我们看到，不同优化算法最核心的区别，就是第三步所执行的下降方向：$$\eta_{t}=(\alpha / \sqrt{V_{t}}) \cdot m_{t}$$<br>这个式子中，前半部分是实际的学习率（也即下降步长），后半部分是实际的下降方向。SGD算法的下降方向就是该位置的梯度方向的反方向，带一阶动量的SGD的下降方向则是该位置的一阶动量方向。自适应学习率类优化算法为每个参数设定了不同的学习率，在不同维度上设定不同步长，因此其下降方向是缩放过（scaled）的一阶动量方向。<br>由于下降方向的不同，可能导致不同算法到达完全不同的局部最优点。《An empirical analysis of the optimization of deep network loss surfaces》 这篇论文中做了一个有趣的实验，他们把目标函数值和相应的参数形成的超平面映射到一个三维空间，这样我们可以直观地看到各个算法是如何寻找超平面上的最低点的。<br><img alt="loss" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/loss.png"></p>
<p>上图是论文的实验结果，横纵坐标表示降维后的特征空间，区域颜色则表示目标函数值的变化，红色是高原，蓝色是洼地。他们做的是配对儿实验，让两个算法从同一个初始化位置开始出发，然后对比优化的结果。可以看到，几乎任何两个算法都走到了不同的洼地，他们中间往往隔了一个很高的高原。这就说明，不同算法在高原的时候，选择了不同的下降方向。</p>
<p>8.Adam + SGD组合<br>不同优化算法的优劣依然是未有定论的争议话题。在paper和各类社区看到的反馈，主流的观点认为：Adam等自适应学习率算法对于稀疏数据具有优势，且收敛速度很快；但精调参数的SGD（+Momentum）往往能够取得更好的最终结果。<br>那么我们就会想到，可不可以把这两者结合起来，先用Adam快速下降，再用SGD调优，一举两得？思路简单，但里面有两个技术问题：</p>
<ul>
<li><p>什么时候切换优化算法？——如果切换太晚，Adam可能已经跑到自己的盆地里去了，SGD再怎么好也跑不出来了。</p>
</li>
<li><p>切换算法以后用什么样的学习率？——Adam用的是自适应学习率，依赖的是二阶动量的累积，SGD接着训练的话，用什么样的学习率？</p>
</li>
</ul>
<p>上一篇中提到的论文 Improving Generalization Performance by Switching from Adam to SGD 提出了解决这两个问题的思路。<br>首先来看第二个问题，切换之后的学习率。</p>
<p>Adam的下降方向是：<br>$$\eta_{t}^{\text {Adam}}=(\alpha / \sqrt{V_{t}}) \cdot m_{t}$$</p>
<p>SGD的下降方向是：<br>$$\eta_{t}^{S G D}=\alpha^{S G D} \cdot g_{t}$$</p>
<p>SGD下降方向必定可以分解为Adam下降方向及其正交方向上的两个方向之和，那么其在Adam下降方向上的投影就意味着SGD在Adam算法决定的下降方向上前进的距离，而在Adam下降方向的正交方向上的投影是 SGD 在自己选择的修正方向上前进的距离。</p>
<p>如果SGD要走完Adam未走完的路，那就首先要接过Adam的大旗——沿着$$\eta_{t}^{A d a<br>m}$$方向走一步，而后再沿着其正交方向走相应地一步。<br>这样我们就知道该如何确定SGD的步长（学习率）了——SGD在Adam下降方向上的正交投影，应该正好等于Adam的下降方向（含步长）。也即：$$p r o j_{\eta_{t}^{S G D}}=\eta_{t}^{\text {Adam}}$$<br>解这个方程，我们就可以得到接续进行SGD的学习率：$$\operatorname{proj}<em>{\eta</em>{t}^{S G<br>D}}=\eta_{t}^{\text {Adam}}$$。为了减少噪声影响，我们可以使用移动平移平均值来修正对学习率的估计：$$\begin{array}{c}<br>                                                               \lambda_{t}^{S G D}=\beta_{2} \cdot \lambda_{t-1}^{S G D}+\left(1-\beta_{2}\right) \cdot \alpha_{t}^{S G D} \<br>                                                               \tilde{\lambda}<em>{t}^{S G D}=\lambda</em>{t}^{S G D} /\left(1-\beta_{2}^{t}\right)<br>                                                               \end{array}$$<br>这里直接复用了Adam的beta参数。然后来看第一个参数，何时进行算法的切换。作者提出的方法很简单，那就是当SGD<br>的相应学习率的移动平均值基本不变的时候，即：$$\left|\tilde{\lambda}<em>{t}^{S G D}-\alpha</em>{t}^{S G<br>D}\right|<\epsilon$$。每次迭代完都计算一下SGD接班人的相应学习率，如果发现基本稳定了，那就SGD以$$\tilde{\lambda<br>}_{t}^{S G<br>D}$$为学习率接班前进。不过，这一时机是否是最优的切换时机，作者并没有给出数学证明，只是通过了实验验证了效果，切换时机还是一个很值得深入研究的课题。</p>
<p>9.优化算法常用的tricks<br>最后，分享一些在优化算法的选择和使用方面的一些tricks。</p>
<ul>
<li>首先，各大算法孰优孰劣并无定论。如果是刚入门，优先考虑 SGD+Nesterov Momentum或者Adam.（Standford 231n: The<br>two recommended updates to use are either SGD+Nesterov Momentum or Adam）</li>
<li>选择你熟悉的算法——这样你可以更加熟练地利用你的经验进行调参。</li>
<li>充分了解你的数据——如果模型是非常稀疏的，那么优先考虑自适应学习率的算法。</li>
<li>根据你的需求来选择——在模型设计实验过程中，要快速验证新模型的效果，可以先用Adam进行快速实验优化；在模型上线或者结果发布前，可以用精调的SGD进行模型的极致优化。</li>
<li>先用小数据集进行实验。有论文研究指出，随机梯度下降算法的收敛速度和数据集的大小的关系不大。（The mathematics of stochastic gradient descent are amazingly independent of the training set size. In particular, the asymptotic SGD convergence rates are independent from the sample size. [2]）因此可以先用一个具有代表性的小数据集进行实验，测试一下最好的优化算法，并通过参数搜索来寻找最优的训练参数。</li>
<li>考虑不同算法的组合。先用Adam进行快速下降，而后再换到SGD进行充分的调优。切换策略可以参考本文介绍的方法。</li>
<li>数据集一定要充分的打散（shuffle）。这样在使用自适应学习率算法的时候，可以避免某些特征集中出现，而导致的有时学习过度、有时学习不足，使得下降方向出现偏差的问题。</li>
<li>训练过程中持续监控训练数据和验证数据上的目标函数值以及精度或者AUC等指标的变化情况。对训练数据的监控是要保证模型进行了充分的训练——下降方向正确，且学习率足够高；对验证数据的监控是为了避免出现过拟合。</li>
<li>制定一个合适的学习率衰减策略。可以使用定期衰减策略，比如每过多少个epoch就衰减一次；或者利用精度或者AUC等性能指标来监控，当测试集上的指标不变或者下跌时，就降低学习率。</li>
</ul>
<p>10.补充：指数移动平均值的偏差修正</p>
<p><img alt="bc" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/bc.png"></p>
</body></html>]]></content>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>杨绛先生4句名句</title>
    <url>/2020/04/07/%E6%9D%A8%E7%BB%9B%E5%85%88%E7%94%9F4%E5%8F%A5%E5%90%8D%E5%8F%A5/</url>
    <content><![CDATA[<html><head></head><body><p>“读杨绛的文字更像是聆听一位哲人讲述的那些烟尘往事，在平静、平淡、平凡中有一种卓越的人生追求。”</p>
<a id="more"></a>
<p>1.无论人生上升到了哪一层台阶，阶下有人在仰望你，阶上亦有人在俯视你，你抬头自卑，低头自得，唯有平视，才能看见真实的自己。<br>正如卞之琳在《断章》里面所说：</p>
<p>你站在桥上看风景，</p>
<p>看风景的人在楼上看你，</p>
<p>明月装饰了你的窗子，</p>
<p>你装饰了别人的梦。</p>
<p>2.你的问题主要在于，读书不多而想的太多。</p>
<p>3.如要锻炼一个能做大事的人，必定要叫他吃苦受累，百不称心，才能养成坚忍的性格。</p>
<p>有句话说的特别好：“无论你遇见谁，她都是你生命中该出现的人，绝非偶然，她一定会教会你一些什么。”</p>
<p>所以我们应当相信，无论我们走到哪里，那都是我们该去的地方，经历一些我们该经历的事，遇见我们该遇见的人。</p>
<p>4.人间不会有单纯的快乐，快乐总夹杂着烦恼和忧虑，人间也没有永远。</p>
</body></html>]]></content>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title>数据挖掘导论-第一章绪论</title>
    <url>/2020/04/02/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AF%BC%E8%AE%BA-%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%BB%AA%E8%AE%BA/</url>
    <content><![CDATA[<html><head></head><body><p>数据挖掘：在大型数据存储库中，自动地发现有用信息的过程。</p>
<a id="more"></a>
<p>数据库中的知识发现（Knowledge discovery in database）KDD：将未加工的数据转换为有用信息的整个过程。<br><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/KDD%E4%B8%BB%E8%A6%81%E6%B5%81%E7%A8%8B.jpg"></p>
<p>四种主要数据挖掘任务：预测建模、聚类分析、关联分析和异常检测。</p>
<p>1.预测建模（predictive modeling）</p>
<p>涉及以说明变量函数的方式为目标变量建立模型。主要有分类和回归两种1预测建模任务。</p>
<p>分类（classification）：用于预测离散的目标变量。</p>
<p>回归（regression）：用于预测连续的目标变量。</p>
<p>例子：鸢尾花分类</p>
<p>2.关联分析（association analysis）</p>
<p>用来描述数据中强关联特征的模式。</p>
<p>例子：购物篮分析</p>
<p>3.聚类分析（cluster analysis）</p>
<p>旨在发现紧密相关的观测值组群，使得与属于不同簇的观测值相比，属于同一簇的观测值相互之间尽可能的相似。</p>
<p>例子：文档聚类</p>
<p>4.异常检测（anomaly detection）</p>
<p>识别其特征显著不同于其他数据的观测值。</p>
<p>例子：信用卡欺诈检测</p>
</body></html>]]></content>
      <tags>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title>常用api接口</title>
    <url>/2020/03/30/%E5%B8%B8%E7%94%A8api%E6%8E%A5%E5%8F%A3/</url>
    <content><![CDATA[<html><head></head><body><p>整理了一些常用的api接口。</p>
<p>1.手机号码归属地：<a href="https://www.juhe.cn/docs/api/id/11" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/11</a></p>
<a id="more"></a>
<p>2.历史上的今天：<a href="https://www.juhe.cn/docs/api/id/63" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/63</a></p>
<p>3.股票数据：<a href="https://www.juhe.cn/docs/api/id/21" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/21</a></p>
<p>4.全国wifi：<a href="https://www.juhe.cn/docs/api/id/18" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/18</a></p>
<p>5.星座运势：<a href="https://www.juhe.cn/docs/api/id/29" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/29</a></p>
<p>6.语音识别：<a href="https://www.juhe.cn/docs/api/id/134" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/134</a></p>
<p>7.周公解梦：<a href="https://www.juhe.cn/docs/api/id/64" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/64</a></p>
<p>8.天气预报：<a href="https://www.juhe.cn/docs/api/id/73" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/73</a></p>
<p>9.身份证查询：<a href="https://www.juhe.cn/docs/api/id/38" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/38</a></p>
<p>10.笑话大全：<a href="https://www.juhe.cn/docs/api/id/95" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/95</a></p>
<p>11.邮编查询：<a href="https://www.juhe.cn/docs/api/id/66" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/66</a></p>
<p>12.老黄历：<a href="https://www.juhe.cn/docs/api/id/65" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/65</a></p>
<p>13.网站安全检测：<a href="https://www.juhe.cn/docs/api/id/19" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/19</a></p>
<p>14.电话来电显示：<a href="https://www.juhe.cn/docs/api/id/72" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/72</a></p>
<p>15.基金财务数据：<a href="https://www.juhe.cn/docs/api/id/28" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/28</a></p>
<p>16.成语词典：<a href="https://www.juhe.cn/docs/api/id/157" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/157</a></p>
<p>17.新闻头条：<a href="https://www.juhe.cn/docs/api/id/235" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/235</a></p>
<p>18.IP地址：<a href="https://www.juhe.cn/docs/api/id/1" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/1</a></p>
<p>19.问答机器人: <a href="https://www.juhe.cn/docs/api/id/112" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/112</a></p>
<p>20.汇率：<a href="https://www.juhe.cn/docs/api/id/80" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/80</a></p>
<p>21.电影票房：<a href="https://www.juhe.cn/docs/api/id/44" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/44</a></p>
<p>22.万年历：<a href="https://www.juhe.cn/docs/api/id/177" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/177</a></p>
<p>23.NBA赛事：<a href="https://www.juhe.cn/docs/api/id/92" target="_blank" rel="noopener">https://www.juhe.cn/docs/api/id/92</a></p>
<p>24.豆瓣开放：<a href="https://developers.douban.com/wiki/" target="_blank" rel="noopener">https://developers.douban.com/wiki/</a></p>
<p>25.淘宝开放：<a href="http://open.taobao.com/" target="_blank" rel="noopener">http://open.taobao.com/</a></p>
<p>26.图灵语音：<a href="http://www.tuling123.com/help/h_cent_andriodsdk.jhtml" target="_blank" rel="noopener">http://www.tuling123.com/help/h_cent_andriodsdk.jhtml</a></p>
<p>27.讯飞语音：<a href="http://www.xfyun.cn/robots/solution" target="_blank" rel="noopener">http://www.xfyun.cn/robots/solution</a></p>
<p>28.腾讯开放平台：<a href="https://open.weixin.qq.com" target="_blank" rel="noopener">https://open.weixin.qq.com</a></p>
<p>29.融云：<a href="https://developer.rongcloud.cn/signin" target="_blank" rel="noopener">https://developer.rongcloud.cn/signin</a></p>
<p>30.百度开发者：<a href="http://developer.baidu.com/" target="_blank" rel="noopener">http://developer.baidu.com/</a></p>
<p>31.人脸识别：<a href="http://www.faceplusplus.com.cn/" target="_blank" rel="noopener">http://www.faceplusplus.com.cn/</a></p>
<p>32.高德地图：<a href="http://lbs.amap.com/" target="_blank" rel="noopener">http://lbs.amap.com/</a></p>
<p>33.蜻蜓FM：<a href="http://open.qingting.fm" target="_blank" rel="noopener">http://open.qingting.fm</a></p>
</body></html>]]></content>
      <tags>
        <tag>Technology Blog</tag>
        <tag>api</tag>
      </tags>
  </entry>
  <entry>
    <title>论文写作之introduction</title>
    <url>/2020/03/29/paper-introduction/</url>
    <content><![CDATA[<html><head></head><body><p>本篇为introduction的写法.</p>
<p>1.介绍领域的大背景，然后逐渐聚焦到研究的内容上（研究背景 重要性）</p>
<p>2.描述与评价相关内容的研究进展和前言，指出研究GAP（重要性 GAP 综述全面）</p>
<p>3.说明本文针对的问题，有哪些难点（问题难点）</p>
<p>4.提出本文采用的解决办法，简单描述（重点描述方法的创新之处）</p>
<p>5.说明文章的创新点和贡献（创新点和贡献）</p>
<p>6.简要说明文章的结构</p>
<p>其中2和3可以合并来写，先指出研究的问题，然后说明有哪些难点，分别针对每个难点，描述之前有哪些研究，怎样解决的，最后总结还有哪些没解决/没解决好的。</p>
</body></html>]]></content>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>论文写作之abstract</title>
    <url>/2020/03/29/paper-abstract/</url>
    <content><![CDATA[<html><head></head><body><p>最近在学习写论文的套路，整理了一下。本篇为abstract的写法。</p>
<p>1.describe the problem and its importance</p>
<p>2.describe difficulties and unsolved issues</p>
<p>3.what methods are proposed in this paper</p>
<p>4.how the proposed method solves the problem</p>
<p>5.what results, contributions, and applications have the methods achieved, and how these can be studied in the future</p>
</body></html>]]></content>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>遇上百分百女孩（下）</title>
    <url>/2020/03/26/%E9%81%87%E4%B8%8A%E7%99%BE%E5%88%86%E7%99%BE%E5%A5%B3%E5%AD%A9%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
    <content><![CDATA[<html><head></head><body><p>很久很久以前，有个地方有一个少男和少女。少男18少女16。少男算不得英俊，少女也不怎么漂亮，无非随处可见的孤独而平常的少男少女。但两人一直坚信着世上有某个地方一定存在着百分之百适合自己的少女和少男。是的，两人相信奇迹，而奇迹真发生了。</p>
<a id="more"></a>
<p>一天两人在街头不期而遇。</p>
<p>“真巧！我一直在寻找你。也许你不相信，你对我是百分之百的男孩。从头到脚跟我想象的一模一样。简直是在做梦。”两人坐在公园长椅上，手拉手，百谈不厌。两人已不再孤单。百分之百需求对方，百分之百已被对方需求。而百分之百需求对方和百分之百地被对方需求是何等美妙的事情啊！这已是宇宙奇迹！</p>
<p>但两人心中掠过一个小小的，的确小而又小的疑虑：梦想如此轻易成真是否就是好事？</p>
<p>交谈突然中断时，少男这样说道：“我说，再尝试一次吧！如果我们两人真是一对百分之百的恋人的话，肯定还会有一天在哪里相遇。下次相遇时如果仍觉得对方百分之百，就马上在那里结婚，好么？”“好的。”少女回答。</p>
<p>于是两人分开，各奔东西。</p>
<p>然而说实话，更本没必要尝试，纯属多此一举。为什么呢？因为两人的的确确是一对百分之百的恋人，因为那是奇迹般的邂逅。但两人过于年轻，没办法知道这许多。于是无情的命运开始捉弄两人。</p>
<p>一年冬天，两人都染上了那年肆虐的恶性流感。在死亡线徘徊几个星期后，过去的记忆丧失殆尽，事情也真是离奇。当两人睁眼醒来时，脑袋里犹如D<br>.H劳伦斯少年时代的贮币盒一样空空如也。</p>
<p>但这对青年男女毕竟聪颖豁达且极有毅力，经过不懈努力，终于再度获得了新的知识新的情感，胜任愉快地重返社会生活。啊，我的上帝！这俩人真是无可挑剔！他们完全能够换乘地铁，能够在邮局寄交快信。并且分别体验了百分之七十五和百分之八十五的恋爱。</p>
<p>如此一来二去，少男32，少女31岁了。时光以惊人的速度流逝。</p>
<p>四月的一个晴朗的早晨，少男为喝折价咖啡沿原宿后街由西向东走，少女为买快信邮票沿东向西走，俩人恰在路中间失之交臂。失去的记忆的微光刹那间照亮两颗心。</p>
<p>俩人胸口陡然悸颤，并且得知：她对我是百分之百的男孩。然而俩人的记忆的烛光委实过于微弱，俩人的话语也不似十四年前那般清晰。结果连句话也没说便擦肩而过，径直消失在人群中，永远永远。</p>
<p>你不觉得这是个令人感伤的故事么？</p>
<p>是的，我本该这样向她搭话。</p>
<p><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/divorce.jpg"></p>
</body></html>]]></content>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title>遇上百分百女孩（上）</title>
    <url>/2020/03/26/%E9%81%87%E4%B8%8A%E7%99%BE%E5%88%86%E7%99%BE%E5%A5%B3%E5%AD%A9%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
    <content><![CDATA[<html><head></head><body><p>四月一个晴朗的早晨，我在原宿后街同一个百分之百的女孩擦肩而过。</p>
<a id="more"></a>
<p>不讳的说，女孩儿算不得怎么漂亮，并无吸引人之处，衣着也不出众，脑后的头发执着带有睡觉挤压的痕迹。年龄也已经不小了—应该快有30了。严格地来说，恐怕很难称之为女孩。然而，相距50米开外我便一眼看出：对我来说，她是个百分之百的女孩。从看见她身资的那一瞬间，我的胸口便如同发生地鸣一般的震颤，口中如沙漠干的沙沙作响。</p>
<p>或许你也有你的理想女孩。例如喜欢足颈细弱的女孩，毕竟眼睛大的女孩，十指绝对好看的女孩，或不明所以地迷上慢慢花时间进食的女孩。我当然也有自己的偏爱。在饭店时就曾看邻桌一个女孩的鼻形看的发呆。但要明确勾勒百分之百的女孩形象，任何人都无法做到。我就绝对想不到她长有怎样的鼻子。甚至是否有鼻子都已记不真切。现在我所能记的，只有她并非十分漂亮这一点。事实也真是不可思议。</p>
<p>“昨天在路上同一个百分之百的女孩擦肩而过。”我对一个人说。</p>
<p>“唔，”他应到，“人可漂亮？”</p>
<p>“不，不是说这个。”</p>
<p>“那，是合你口味那种类型喽？”</p>
<p>“记不得了。眼睛什么样啦，胸部是大是小啦，统统忘得一干二净。”</p>
<p>“莫名其妙啊！”</p>
<p>“是莫名其妙。”</p>
<p>“那么，”他显的兴味索然，“你做什么了？搭话了？还是跟踪了？”</p>
<p>“什么都没有做。”我说，“仅仅是擦肩而过。”</p>
<p>她由东往西走，我从西往东去，在四月里一个神清气爽的早晨。</p>
<p>我想和她说话，哪怕30分钟也好。想打听她的身世，也想全盘拖出自己的身世。而更重要的，是想弄清导致1981年4月一个晴朗的早晨我们在原宿后街擦肩而过这一命运的原委。里面肯定有充满和平时代的古老机器般温馨的秘密。</p>
<p>如此谈罢，我们可以找地方吃饭，看伍迪.爱伦的影片，再顺路到宾馆里的酒吧喝鸡尾酒什么的。弄不好，喝完说不定能同她睡上一觉。可能性在叩击我的心扉。我和她之间的距离已近至十五六米了。问题是，我到底该如何向她搭话呢？</p>
<p>“你好！和我说说话可以吗？哪怕30分钟也好。”过于傻气，简直像劝人加入保险。“请问，这一带有24小时营业的洗衣店吗？”这也同样傻里傻气。何况我岂非连洗衣袋都没带！有谁能相信我的道白呢？也许开门见山的好些。“你好！你对我可是百分之百的女孩呦！”</p>
<p>不，不成，她恐怕不会相信我的表白。纵然相信，也未必愿同我说什么话。她可能这样说：即使我对你是百分之百的女孩，你对我可不是百分之百的男人，抱歉！而这是大有可能的。如果陷入这般境地，我肯定全然不知所措。这一打击说不定使我一蹶不振。我已32岁，所谓上了年纪归根结底便是这么一回事。</p>
<p>我是在花店门前和她擦肩而过的，那暖暖的小小的气块儿触到我的肌肤。柏油路面洒了水，周围荡漾着玫瑰花香。连向她打声招呼我都未能做到。她身穿毛衣，右手拿着一个尚未贴邮票的四方信封。她给谁写了封信。那般睡眼惺忪，说不定写了整整一个晚上。那四方信封里有可能装有她的全部秘密。走几步回头时，她的身影早已消失在人群中。</p>
<p>当然，今天我已完全清楚当时应该怎样向她搭话。但不管怎么说，那道白实在太长，我笃定表达不好—就是这样，我所想到的每每不够实用。总之，道白自“很久很久以前”开始，而以“你不觉得这是个忧伤的故事吗”结束。</p>
<p><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/love.jpg"></p>
</body></html>]]></content>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title>远行，方有一种心境</title>
    <url>/2020/03/21/%E8%BF%9C%E8%A1%8C%EF%BC%8C%E6%96%B9%E6%9C%89%E4%B8%80%E7%A7%8D%E5%BF%83%E5%A2%83/</url>
    <content><![CDATA[<html><head></head><body><p>夜阑人静</p>
<p>偶闻遥远的吠声</p>
<a id="more"></a>
<p>在这远离故乡的地方</p>
<p>树影婆娑如梦</p>
<p>思绪缓缓地流动</p>
<p>忆起少年往事</p>
<p>往事像窗外的流萤</p>
<p>有几多可笑 几多烦恼</p>
<p>全被岁月一一抚平</p>
<p>不知为什么</p>
<p>今夕 会想起太多</p>
<p>或许</p>
<p>远行，方有一种心境</p>
</body></html>]]></content>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title>怀恋</title>
    <url>/2020/03/19/%E6%80%80%E6%81%8B/</url>
    <content><![CDATA[<html><head></head><body><p>终于你也懂得了，</p>
<p>自己之所以会想念他，</p>
<p>其实并不是因为他的好，</p>
<p>而是因为，</p>
<p>之后再也没有一个人可以让你觉得好，</p>
<p>你怀恋的，自始至终，都是爱。</p>
</body></html>]]></content>
      <tags>
        <tag>love</tag>
      </tags>
  </entry>
  <entry>
    <title>Github官方App</title>
    <url>/2020/03/18/Github%E5%AE%98%E6%96%B9App/</url>
    <content><![CDATA[<html><head></head><body><p>Github官方App发布，官网下载地址:<a href="https://github.com/mobile" target="_blank" rel="noopener">https://github.com/mobile</a></p>
<p>百度网盘分享: <a href="https://pan.baidu.com/s/1RA8byuybDUJV6n4TPze_Cg" target="_blank" rel="noopener">https://pan.baidu.com/s/1RA8byuybDUJV6n4TPze_Cg</a> 提取码：fyyr</p>
</body></html>]]></content>
      <tags>
        <tag>Technology Blog</tag>
      </tags>
  </entry>
  <entry>
    <title>补上前些日子的</title>
    <url>/2020/03/16/2020-03-16/</url>
    <content><![CDATA[<html><head></head><body><p>我没遇到你是我的遗憾，你没遇到我是你的遗憾，为什么我们要让自己充满遗憾。</p>
<a id="more"></a>
<p>凡为过去，皆为序章。</p>
<p>如果结果还不够好，那就是还没到剧终。</p>
<p>“不是两情相悦才是爱吗？”“相爱是很难的，更多的是像我这样的。”</p>
<p>你知道我得鼓起多大勇气和你说这些吗，我要亲口告诉你，是我不对，我说了我还有一半的机会，如果我不说，我就永远没有机会了。</p>
<p>你知道比悲伤更悲伤的事情是什么吗？比悲伤更悲伤的是空欢喜。</p>
<p>人的出场顺序真的很重要，不是你不好，而是相遇太晚，要走的人留不住。</p>
<p><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/ironman.jpg"></p>
</body></html>]]></content>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title>皮囊</title>
    <url>/2020/03/15/beautiful-sentences/</url>
    <content><![CDATA[<html><head></head><body><p>“当你坐在一个人面前，听她说话，看的到各种复杂、精密的情况和命运，如何才能最终雕<br>刻这样的性格、思想、做法、长相，这才是理解。。。也会发觉：这世界最美丽的风景，是<br>一个一个活出各自模样和体系的人。”生活从来不会无聊寡淡，只要你懂得欣赏眼前的风景。</p>
<a id="more"></a>
<p><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/girl.jpg"></p>
</body></html>]]></content>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux系统更换yum源</title>
    <url>/2020/03/15/Linux%E7%B3%BB%E7%BB%9F%E6%9B%B4%E6%8D%A2yum%E6%BA%90/</url>
    <content><![CDATA[<html><head></head><body><h2 id="Linux简介"><a href="#Linux简介" class="headerlink" title="Linux简介"></a>Linux简介</h2><a id="more"></a>
<p>目前在长期稳定运行的网站服务器、处理大量数据的集群系统以及需要协同工作的环境中都<br>大量采用Linux系统。相较于Windows系统而言，Linux系统具有以下优势：<br>1.稳定且有效率 2.免费或少许费用 3.漏洞少且快速修补 4.多任务多用户<br>5.更加安全的用户及文件权限策略 6.适合小内核程序的嵌入系统 7.相对不耗资源</p>
<p><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/Linux_vs_Windows.jpg"></p>
<p>常见的Linux系统有如下几种：</p>
<p>红帽企业版（RedHat Enterprise Linux）：RHEL是全世界内使用最广泛的Linux系统。</p>
<p>社区企业操作系统（Communicity Enterprise Operating System, CentOS ）：RHEL重新编译发布的免费Linux系统。</p>
<p>Fedora：红帽公司发布的桌面版系统套件。</p>
<p>openSUSE：德国的一款著名Linux系统。</p>
<p>Gentoo：具有极高的自定制性，操作复杂。</p>
<p>Debian：稳定性、安全性强，可以良好地支持各种硬件架构。</p>
<p>Ubuntu：对新款硬件具有极强的兼容能力。</p>
<p>然而没有注册的RHEL是无法使用yum来安装软件的，为此需要将yum源更换成CentOS的免费源来解决包的依赖问题。</p>
<h2 id="更换yum源"><a href="#更换yum源" class="headerlink" title="更换yum源"></a>更换yum源</h2><p>打开虚拟机（作者的红帽是装在虚拟机上的）终端执行</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">rpm -qa | grep yum</span><br></pre></td></tr></tbody></table></figure>
<p>系统将会显示自带的yum源，<br>删除系统自带的yum组件</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">rpm -qa | grep yum | xargs rpm -e --nodeps</span><br></pre></td></tr></tbody></table></figure>
<p>进入<a href="http://mirrors.163.com" target="_blank" rel="noopener">网易163源镜像地址</a>，在路径centos/7/os/x86_64/Packages/下载（可以在物理机上下载或者在虚拟机上使用wget下载）python-iniparse-0.4-9.el7.noarch、python-iniparse-0.4-9.el7.noarch、yum-3.4.3-161.el7.centos.noarch、yum-metadata-parser-1.1.4-10.el7.x86_64、yum-plugin-fastestmirror-1.1.31-50.el7.noarch这五个包。</p>
<p>安装软件包</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">rpm -ivh yum-*</span><br><span class="line"># 此时会报依赖的错误</span><br><span class="line">rpm >= 0:4.11.3-35 is needed by yum-3.4.3-161.el7.centos.noarch</span><br></pre></td></tr></tbody></table></figure>
<p>下载rpm-4.11.3-35.el7.x86_64包并重新安装</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">rpm -Uvh rpm-4.11.3-35.el7.x86_64.rpm --nodeps</span><br><span class="line">rpm -ivh yum-*</span><br></pre></td></tr></tbody></table></figure>
<p>更新yum源文件，可以下载使用163的yum源文件CentOS6-Base-163，放在/etc/yum.repo.d目录下</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">vim /etc/yum.repos.d/CentOS-Base.repo</span><br></pre></td></tr></tbody></table></figure>
<p>内容如下，将$releasever改成7即可</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># CentOS-Base.repo</span><br><span class="line">#</span><br><span class="line"># The mirror system uses the connecting IP address of the client and the</span><br><span class="line"># update status of each mirror to pick mirrors that are updated to and</span><br><span class="line"># geographically close to the client.  You should use this for CentOS updates</span><br><span class="line"># unless you are manually picking other mirrors.</span><br><span class="line">#</span><br><span class="line"># If the mirrorlist= does not work for you, as a fall back you can try the </span><br><span class="line"># remarked out baseurl= line instead.</span><br><span class="line">#</span><br><span class="line">#</span><br><span class="line"></span><br><span class="line">[base]</span><br><span class="line">name=CentOS-7 - Base - 163.com</span><br><span class="line">baseurl=http://mirrors.163.com/centos/7/os/$basearch/</span><br><span class="line">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=os</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-6</span><br><span class="line"></span><br><span class="line">#released updates </span><br><span class="line">[updates]</span><br><span class="line">name=CentOS-7 - Updates - 163.com</span><br><span class="line">baseurl=http://mirrors.163.com/centos/7/updates/$basearch/</span><br><span class="line">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=updates</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-7</span><br><span class="line"></span><br><span class="line">#additional packages that may be useful</span><br><span class="line">[extras]</span><br><span class="line">name=CentOS-7 - Extras - 163.com</span><br><span class="line">baseurl=http://mirrors.163.com/centos/7/extras/$basearch/</span><br><span class="line">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=extras</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-7</span><br><span class="line"></span><br><span class="line">#additional packages that extend functionality of existing packages</span><br><span class="line">[centosplus]</span><br><span class="line">name=CentOS-7 - Plus - 163.com</span><br><span class="line">baseurl=http://mirrors.163.com/centos/7/centosplus/$basearch/</span><br><span class="line">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=centosplus</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=0</span><br><span class="line">gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-7</span><br><span class="line"></span><br><span class="line">#contrib - packages by Centos Users</span><br><span class="line">[contrib]</span><br><span class="line">name=CentOS-7 - Contrib - 163.com</span><br><span class="line">baseurl=http://mirrors.163.com/centos/7/contrib/$basearch/</span><br><span class="line">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=contrib</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=0</span><br><span class="line">gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-7</span><br></pre></td></tr></tbody></table></figure>
<p>清除yum缓存</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">yum clean all</span><br><span class="line"># 生成缓存</span><br><span class="line">yum makeche</span><br><span class="line"># 查看新源</span><br><span class="line">yum repolist</span><br><span class="line">yum repolist</span><br><span class="line">repo id                      repo name                             status</span><br><span class="line">!base/x86_64                 CentOS-$7 - Base - 163.com             8,652</span><br><span class="line">!extras/x86_64               CentOS-$7 - Extras - 163.com           275</span><br><span class="line">!updates/x86_64              CentOS-$7 - Updates - 163.com          1,707</span><br><span class="line">repolist: 10,634</span><br></pre></td></tr></tbody></table></figure>
<p>yum源已更换成功，下面就可以自由使用yum安装软件啦。</p>
<p>附：<a href="https://pan.baidu.com/s/1lUSU9PdFOpmji2kSKnO1NA" target="_blank" rel="noopener">本文所需rpm及repo</a><br>提取码：rp3l</p>
<p>参考：</p>
<p>Linux就该这么学</p>
<p><a href="https://blog.csdn.net/eddy_chan/article/details/54728385" target="_blank" rel="noopener">https://blog.csdn.net/eddy_chan/article/details/54728385</a></p>
</body></html>]]></content>
      <tags>
        <tag>Technology Blog</tag>
        <tag>Linux</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux环境下安装python3.x</title>
    <url>/2020/03/15/Linux%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%AE%89%E8%A3%85python3-x/</url>
    <content><![CDATA[<html><head></head><body><h2 id="Linux下python版本"><a href="#Linux下python版本" class="headerlink" title="Linux下python版本"></a>Linux下python版本</h2><p>目前Linux下的绝大部分系统都自带了python2.x的版本,而现在python的主流版本已经到了3.x。为此我们需要将python3.x安装在自己的Linux系统上。</p>
<a id="more"></a>
<p>查看python版本</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">[root@xiaohui ~]# python --version</span><br><span class="line">Python 2.7.5</span><br></pre></td></tr></tbody></table></figure>
<h2 id="安装python3步骤"><a href="#安装python3步骤" class="headerlink" title="安装python3步骤"></a>安装python3步骤</h2><p>1.使用wget下载python3.x的安装包</p>
<p>笔者下载的是3.7.1的版本，其余的版本也可根据自己的需要进行下载</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">[root@xiaohui ~]# wget https://www.python.org/ftp/python/3.7.1/Python-3.7.1rc2.tgz</span><br></pre></td></tr></tbody></table></figure>
<p>2.创建存放python3.x的文件夹</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">[root@xiaohui ~]# mkdir  /usr/local/python3/</span><br></pre></td></tr></tbody></table></figure>
<p>3.将压缩包移至创建的文件夹内并切换至该文件夹解压安装包</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">[root@xiaohui ~]# mv Python-3.7.1rc2.tgz /usr/local/python3</span><br><span class="line">[root@xiaohui ~]# cd  /usr/local/python3</span><br><span class="line">[root@xiaohui python3]# tar -zxf  Python-3.7.1rc2.tgz</span><br></pre></td></tr></tbody></table></figure>
<p>4.切换至解压的文件夹</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">[root@xiaohui python3]# cd ./Python-3.7.1rc2</span><br></pre></td></tr></tbody></table></figure>
<p>5.配置、编译和执行安装</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">[root@xiaohui Python-3.7.1rc2]# ./configure --with-ssl</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">[root@xiaohui Python-3.7.1rc2]# make</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">[root@xiaohui Python-3.7.1rc2]# make install</span><br><span class="line">...</span><br><span class="line"># 安装成功显示</span><br><span class="line">Collecting setuptools</span><br><span class="line">Collecting pip</span><br><span class="line">Installing collected packages: setuptools, pip</span><br><span class="line">Successfully installed pip-10.0.1 setuptools-39.0.1</span><br></pre></td></tr></tbody></table></figure>
<p>步骤5中可能会出现一些errors，主要是缺少相应的依赖包，只需要通过yum安装对应的依赖包即可解决。笔者就遇到了三个errors</p>
<p>错误1 缺少gcc</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 错误代码</span><br><span class="line">configure: error: no acceptable C compiler found in $PATH</span><br></pre></td></tr></tbody></table></figure>
<p>该错误是因为本机缺少gcc编译环境，只需安装gcc即可</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 安装命令</span><br><span class="line">[root@xiaohui Python-3.7.1rc2]# yum install -y gcc</span><br></pre></td></tr></tbody></table></figure>
<p>错误2 缺少zlib</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 错误代码</span><br><span class="line">zipimport.ZipImportError: can't decompress data; zlib not available</span><br></pre></td></tr></tbody></table></figure>
<p>该错误是因为本机缺少zlib解压缩类库，只需安装zlib即可</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 安装命令</span><br><span class="line">[root@xiaohui Python-3.7.1rc2]# yum install -y zlib*</span><br></pre></td></tr></tbody></table></figure>
<p>错误3 缺少libffi-devel</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 错误代码</span><br><span class="line">ModuleNotFoundError: No module named '_ctypes'</span><br></pre></td></tr></tbody></table></figure>
<p>该错误是因为本机缺少libffi-devel包，只需安装此包即可</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 安装命令</span><br><span class="line">[root@xiaohui Python-3.7.1rc2]# yum install -y libffi-devel</span><br></pre></td></tr></tbody></table></figure>
<p>注意在安装完缺少的依赖包后，仍需重新运行对应所在的配置、编译和执行安装命令</p>
<p>6.配置及建立软链接</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 将python库路径添加到/etc/ld.so.conf配置中</span><br><span class="line"># ld.so.conf文件是存储etc目录下的所有.conf文件</span><br><span class="line">[root@xiaohui Python-3.7.1rc2]# echo "/usr/python/lib" >> /etc/ld.so.conf</span><br><span class="line">[root@xiaohui Python-3.7.1rc2]# ldconfig</span><br><span class="line"># 建立新的软链接至python3.x，原本旧链接无需删除</span><br><span class="line"># 原因在于例如CentOS的yum源是用python2.x编写的，删除可能会出一些错误</span><br><span class="line">[root@xiaohui Python-3.7.1rc2]# ln -s /usr/python/bin/python3 /usr/bin/python3</span><br><span class="line">[root@xiaohui Python-3.7.1rc2]# ln -s /usr/python/bin/pip3 /usr/bin/pip3</span><br></pre></td></tr></tbody></table></figure>
<p>经过上述步骤后则成功完成了python3.x的安装，我们可以检测系统的python版本</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">[root@xiaohui ~]# python3 --version</span><br><span class="line">Python 3.7.1rc2</span><br><span class="line"># python2.x依旧存在</span><br><span class="line">[root@xiaohui ~]# python2 --version</span><br><span class="line">Python 2.7.5</span><br></pre></td></tr></tbody></table></figure>
<p>使用pip3测试</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">[root@xiaohui Python-3.7.1rc2]# pip3 list</span><br><span class="line">Package    Version </span><br><span class="line">---------- --------</span><br><span class="line">certifi    2019.3.9</span><br><span class="line">chardet    3.0.4   </span><br><span class="line">future     0.17.1  </span><br><span class="line">idna       2.8     </span><br><span class="line">itchat     1.2.32  </span><br><span class="line">pip        10.0.1  </span><br><span class="line">pypng      0.0.19  </span><br><span class="line">PyQRCode   1.2.1   </span><br><span class="line">requests   2.21.0  </span><br><span class="line">setuptools 39.0.1  </span><br><span class="line">urllib3    1.24.3  </span><br><span class="line">wxpy       0.3.9.8 </span><br><span class="line">You are using pip version 10.0.1, however version 19.1.1 is available.</span><br><span class="line">You should consider upgrading via the 'pip install --upgrade pip' command.</span><br></pre></td></tr></tbody></table></figure>
<p>测试成功，python3已成功安装在本Linux系统上</p>
</body></html>]]></content>
      <tags>
        <tag>Technology Blog</tag>
        <tag>Linux</tag>
        <tag>Python3-x</tag>
      </tags>
  </entry>
  <entry>
    <title>爬取拉钩python数据分析职位招聘信息</title>
    <url>/2020/03/15/python%E7%88%AC%E5%8F%96%E6%8B%89%E9%92%A9python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E8%81%8C%E4%BD%8D%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF/</url>
    <content><![CDATA[<html><head></head><body><h2 id="python数据分析"><a href="#python数据分析" class="headerlink" title="python数据分析"></a>python数据分析</h2><p>python数据分析是目前python最火的方向之一，为了解目前市场对该职位的需求，<br>我们爬取了拉钩上对pythons数据分析的招聘信息。</p>
<a id="more"></a>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><blockquote>
<p>系统：windows7</p>
</blockquote>
<blockquote>
<p>python版本：3.7.1</p>
</blockquote>
<h2 id="爬虫分析"><a href="#爬虫分析" class="headerlink" title="爬虫分析"></a>爬虫分析</h2><p>1.谷歌浏览器打开拉钩官网<a href="https://www.lagou.com/，搜索框中输入要查询的职位，" target="_blank" rel="noopener">https://www.lagou.com/，搜索框中输入要查询的职位，</a><br>右键点击检查，找到名为positionAjax.json?needAddtionalResult=false的链接，<br>这就是我们要重点分析的地方。</p>
<p><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/1.png"><br>抱着侥幸心理我们将链接<a href="https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false输入浏览器中，" target="_blank" rel="noopener">https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false输入浏览器中，</a><br>发现提示：{“status”:false,”msg”:”您操作太频繁,请稍后再访问”,”clientIp”:”113.57.183.6”,”state”:2402}<br>可见想要获取信息不是那么简单。</p>
<p>2.分析报文<br>首先发送get请求，获取session</p>
<p><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/7.png"></p>
<p>session更新，发送post请求</p>
<p><img alt="图片" data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci8yLnBuZw?x-oss-process=image/format,png"></p>
<p><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/3.png"><br>比较发现get请求和pos请求参数一致，这无疑减少了我们的工作量</p>
<p><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/8.png"></p>
<p><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/9.png"></p>
<p><img alt="图片" data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci80LnBuZw?x-oss-process=image/format,png"></p>
<p>分析翻页，点击下一页则会新增一天get请求，并且Form Data中的pn则会加1，这是翻页的关键</p>
<p><img alt="图片" data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci81LnBuZw?x-oss-process=image/format,png"></p>
<p><img alt="图片" data-src="https://raw.githubusercontent.com/xiaohui96/picture/master/6.png"><br>分析数据结构，选择需要存储的信息</p>
<p><img alt="图片" data-src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL3hpYW9odWk5Ni9waWN0dXJlL21hc3Rlci8xMC5wbmc?x-oss-process=image/format,png"></p>
<p>分析完报文后就理清了我们的爬虫思路，首先构造get请求获取session;；更新session，发送post请求；通过改变Form Data中的pn值<br>实现翻页循环；获取并存储数据</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>1.构造get请求</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def get_json(url, data):</span><br><span class="line">    # 构造随机请求头</span><br><span class="line">    for i in range(100):</span><br><span class="line">        ua = UserAgent()</span><br><span class="line">        # print(ua.random)</span><br><span class="line"></span><br><span class="line">    my_headers = {</span><br><span class="line">        # "User-Agent": "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) "</span><br><span class="line">        # "Chrome/67.0.3396.99 Safari/537.36",</span><br><span class="line">        "User-Agent": "ua.random",</span><br><span class="line">        "Referer": "https://www.lagou.com/jobs/list_python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"</span><br><span class="line">                   "?city=%E5%85%A8%E5%9B%BD&cl=false&fromSearch=true&labelWords=&suginput=",</span><br><span class="line">        "Content-Type": "application/json;charset=UTF-8"}</span><br></pre></td></tr></tbody></table></figure>
<p>get请求主要由User_Agent, Referer和Content-Type组成，其中后两者可从上文报文中获取，为减少爬虫次数过多而被封，我们可通过<br>UserAgent构造随机请求头。UserAgent可通过pip install fake_useragent获得。下图是随机生成的请求头。</p>
<p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-xDkr5qVQ-1584262486509)(<a href="https://raw.githubusercontent.com/xiaohui96/picture/master/11.png)]" target="_blank" rel="noopener">https://raw.githubusercontent.com/xiaohui96/picture/master/11.png)]</a></p>
<p>2.获取并更新session，发送post请求</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 获取session</span><br><span class="line">   session = requests.session()</span><br><span class="line">   # 更新</span><br><span class="line">   session.headers.update(my_headers)</span><br><span class="line">   session.get(</span><br><span class="line">       "https://www.lagou.com/jobs/list_python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"</span><br><span class="line">       "?city=%E5%85%A8%E5%9B%BD&cl=false&fromSearch=true&labelWords=&suginput=")</span><br><span class="line">   content = session.post(url=url, data=data)</span><br></pre></td></tr></tbody></table></figure>
<p>3.构造翻页</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">for num in range(1, page + 1):</span><br><span class="line">    url = 'https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false'</span><br><span class="line">    data = {</span><br><span class="line">        'first': 'false',</span><br><span class="line">        'pg': num,</span><br><span class="line">        'kd': 'python数据分析',</span><br><span class="line">    }</span><br></pre></td></tr></tbody></table></figure>
<p>4.存储数据</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 创建workbook,即excel</span><br><span class="line">        workbook = xlwt.Workbook(encoding='utf-8')</span><br><span class="line">        # 创建表,第二参数用于确认同一个cell单元是否可以重设值</span><br><span class="line">        worksheet = workbook.add_sheet('python数据分析', cell_overwrite_ok=True)</span><br><span class="line">        for i, row in enumerate(info_result):</span><br><span class="line">            # print(row)</span><br><span class="line">            for j, col in enumerate(row):</span><br><span class="line">                # print(col)</span><br><span class="line">                worksheet.write(i, j, col)</span><br><span class="line">        workbook.save('python数据分析.xls')</span><br></pre></td></tr></tbody></table></figure>
<p>以上就是爬虫总体代码思路，完整代码如下:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># encoding: utf-8</span><br><span class="line">"""</span><br><span class="line">@author: xiaohui</span><br><span class="line">@contact: xiaohui1295371450@163.com</span><br><span class="line">@file: crawl.py</span><br><span class="line">@time: 2019-05-14 10:44</span><br><span class="line">@desc: crawl data on lagou</span><br><span class="line">"""</span><br><span class="line">import json</span><br><span class="line">import requests</span><br><span class="line">import xlwt</span><br><span class="line">import time</span><br><span class="line">from fake_useragent import UserAgent</span><br><span class="line"></span><br><span class="line"># 获取存储职位信息的json对象，遍历获得城市、公司名称、工作地点、学历要求、职位名称、薪资、工作年限</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_json(url, data):</span><br><span class="line">    # 构造随机请求头</span><br><span class="line">    for i in range(100):</span><br><span class="line">        ua = UserAgent()</span><br><span class="line">        print(ua.random)</span><br><span class="line"></span><br><span class="line">    my_headers = {</span><br><span class="line">        # "User-Agent": "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) "</span><br><span class="line">        # "Chrome/67.0.3396.99 Safari/537.36",</span><br><span class="line">        "User-Agent": "ua.random",</span><br><span class="line">        "Referer": "https://www.lagou.com/jobs/list_python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"</span><br><span class="line">                   "?city=%E5%85%A8%E5%9B%BD&cl=false&fromSearch=true&labelWords=&suginput=",</span><br><span class="line">        "Content-Type": "application/json;charset=UTF-8"}</span><br><span class="line">    time.sleep(5)</span><br><span class="line">    # 获取session</span><br><span class="line">    session = requests.session()</span><br><span class="line">    # 更新</span><br><span class="line">    session.headers.update(my_headers)</span><br><span class="line">    session.get(</span><br><span class="line">        "https://www.lagou.com/jobs/list_python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"</span><br><span class="line">        "?city=%E5%85%A8%E5%9B%BD&cl=false&fromSearch=true&labelWords=&suginput=")</span><br><span class="line">    content = session.post(url=url, data=data)</span><br><span class="line">    result = content.json()</span><br><span class="line">    info = result['content']['positionResult']['result']</span><br><span class="line">    info_list = []</span><br><span class="line">    information = []</span><br><span class="line">    for job in info:</span><br><span class="line">        # 城市</span><br><span class="line">        information.append(job['city'])</span><br><span class="line">        # 公司全名</span><br><span class="line">        information.append(job['companyFullName'])</span><br><span class="line">        # 工作地点</span><br><span class="line">        information.append(job['district'])</span><br><span class="line">        # 学历要求</span><br><span class="line">        information.append(job['education'])</span><br><span class="line">        # 职位名称</span><br><span class="line">        information.append(job['positionName'])</span><br><span class="line">        # 薪资</span><br><span class="line">        information.append(job['salary'])</span><br><span class="line">        # 工作年限</span><br><span class="line">        information.append(job['workYear'])</span><br><span class="line">        info_list.append(information)</span><br><span class="line">    return info_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    page = int(input('输入爬取的页码总数：'))</span><br><span class="line">    info_result = []</span><br><span class="line">    title = ['城市', '公司全名', '工作地点', '学历要求', '职位名称', '薪资', '工作年限']</span><br><span class="line">    info_result.append(title)</span><br><span class="line">    for num in range(1, page + 1):</span><br><span class="line">        url = 'https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false'</span><br><span class="line">        data = {</span><br><span class="line">            'first': 'false',</span><br><span class="line">            'pg': num,</span><br><span class="line">            'kd': 'python数据分析',</span><br><span class="line">        }</span><br><span class="line">        try:</span><br><span class="line">            info = get_json(url, data)</span><br><span class="line">            info_result = info_result + info</span><br><span class="line">            print("第%s页爬取成功" % num)</span><br><span class="line">        except Exception as msg:</span><br><span class="line">            print("第%s页爬取失败" % num)</span><br><span class="line"></span><br><span class="line">        # 创建workbook,即excel</span><br><span class="line">        workbook = xlwt.Workbook(encoding='utf-8')</span><br><span class="line">        # 创建表,第二参数用于确认同一个cell单元是否可以重设值</span><br><span class="line">        worksheet = workbook.add_sheet('python数据分析', cell_overwrite_ok=True)</span><br><span class="line">        for i, row in enumerate(info_result):</span><br><span class="line">            # print(row)</span><br><span class="line">            for j, col in enumerate(row):</span><br><span class="line">                # print(col)</span><br><span class="line">                worksheet.write(i, j, col)</span><br><span class="line">        workbook.save('python数据分析.xls')</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    main()</span><br></pre></td></tr></tbody></table></figure>
<p>分析我们获得的excel数据，主要招聘地依旧集中在北京、上海和广州，薪资集中在15k-30k之间，可以说情景不错。<br>这不失为度过目前互联网寒冬的一种选择。</p>
<p>附：<a href="https://pan.baidu.com/s/1q8kSg1tvubtLfSK-X525Cg" target="_blank" rel="noopener">完整代码和爬虫数据结果</a><br>提取码：n9d9</p>
</body></html>]]></content>
      <tags>
        <tag>Technology Blog</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下tar解压文件的一个小bug</title>
    <url>/2020/03/15/Linux%E4%B8%8Btar%E8%A7%A3%E5%8E%8B%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8Fbug/</url>
    <content><![CDATA[<html><head></head><body><h2 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h2><p>解压ideaIU-2019.1.2.tar.gz文件，使用命令：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">[root@xiaohui Downloads]# tar xzvf ideaIU-2019.1.2.tar.gz -C /usr/IDEA</span><br></pre></td></tr></tbody></table></figure>
<a id="more"></a>
<h2 id="错误代码："><a href="#错误代码：" class="headerlink" title="错误代码："></a>错误代码：</h2><figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">tar (child): ideaIU-2019.1.2.tar.gz: Cannot open: No such file or directory</span><br><span class="line">tar (child): Error is not recoverable: exiting now</span><br><span class="line">tar: Child returned status 2</span><br><span class="line">tar: Error is not recoverable: exiting now</span><br></pre></td></tr></tbody></table></figure>

<h2 id="场景描述："><a href="#场景描述：" class="headerlink" title="场景描述："></a>场景描述：</h2><p>为避免麻烦我总是喜欢直接切换到root，当我在root情况下使用tar xzvf ideaIU-2019.1.2.tar.gz -C /usr/IDEA时出现上述错误，<br>当我切换到下载路径下进行解压时同样如此。各种尝试之后偶然切换回xiaohui用户并在下载目录下进行解压时出现解压过程，<br>只是提示deny permission。灵机一动的我一想这不就是没有root权限吗，这是我才想起了一直被我忽视的命令—sudo</p>
<h2 id="最终命令"><a href="#最终命令" class="headerlink" title="最终命令"></a>最终命令</h2><p><code>[xiaohui@xiaohui Downloads]$ sudo tar xzvf ideaIU-2019.1.2.tar.gz -C /usr/IDEA</code></p>
<p>解压成功</p>
</body></html>]]></content>
      <tags>
        <tag>Technology Blog</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu环境安装Docker</title>
    <url>/2020/03/15/Ubuntu%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85Docker/</url>
    <content><![CDATA[<html><head></head><body><h2 id="Ubuntu环境安装Docker"><a href="#Ubuntu环境安装Docker" class="headerlink" title="Ubuntu环境安装Docker"></a>Ubuntu环境安装Docker</h2><p>Docker目前支持最低的Ubuntu版本为14.04LTS，从性能上考虑，推荐使用16.04LTS或者18.04LTS版本，并且系统内核越新越好，以支持Docker最新的特性。</p>
<a id="more"></a>
<p>1.系统要求</p>
<p>用户可通过以下命令查看自己的内核版本详细信息</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">xiaohui@xiaohui-virtual-machine:~$ uname -a</span><br><span class="line">Linux xiaohui-virtual-machine 4.18.0-15-generic #16~18.04.1-ubuntu SMP Thu Feb 7 14:06:04 UTC 2019  X86_64 X86_64 X86_64 GNU/Linux</span><br></pre></td></tr></tbody></table></figure>
<p>如果使用的Ubuntu版本是16.04 LTS版本，为了让Docker使用sufs存储，推荐安装下面两个安装包：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">xiaohui@xiaohui-virtual-machine:~$ sudo apt-get update</span><br><span class="line">xiaohui@xiaohui-virtual-machine:~$ sudo apt-get install -y \</span><br><span class="line">linux-image-extra-$(uname -r) \</span><br><span class="line">linux-image-extra-virtual</span><br></pre></td></tr></tbody></table></figure>
<p>2.添加镜像源</p>
<p>首先安装apt-transport-https等软件包支持https协议的源</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">xiaohui@xiaohui-virtual-machine:~$ sudo apt-get update</span><br><span class="line">xiaohui@xiaohui-virtual-machine:~$ sudo apt-get install \ </span><br><span class="line">apt-transport-https \</span><br><span class="line">ca-certificates \</span><br><span class="line">curl \</span><br><span class="line">software-properties-common</span><br></pre></td></tr></tbody></table></figure>
<p>添加源的gpg秘钥</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">xiaohui@xiaohui-virtual-machine:~$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span><br></pre></td></tr></tbody></table></figure>
<p>确认导入指纹为“9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88”的gpg公钥：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">xiaohui@xiaohui-virtual-machine:~$ sudo apt-key fingerprint 0EBFCD88</span><br></pre></td></tr></tbody></table></figure>
<p>获取当前操作系统的代号</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">xiaohui@xiaohui-virtual-machine:~$ lsb_release -cs</span><br><span class="line">bionic</span><br></pre></td></tr></tbody></table></figure>
<p>如果系统是Ubuntu 16.04 LTS，系统代号则为xenial</p>
<p>添加Docker稳定版的官方软件源，注意修改自己的系统代号</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">xiaohui@xiaohui-virtual-machine:~$ sudo add-get-repository \</span><br><span class="line">"deb [arch=amd64] https://download.docker.com/linux/ubuntu \</span><br><span class="line">bionic \</span><br><span class="line">stable"</span><br></pre></td></tr></tbody></table></figure>
<p>添加成功后，再次更新apt软件包缓存</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">xiaohui@xiaohui-virtual-machine:~$sudp apt-get update</span><br></pre></td></tr></tbody></table></figure>
<p>3.开始安装Docker<br>成功添加源之后，可以安装最新版的Docker了，软件包名称为docker-ce，代表是社区版本。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">xiaohui@xiaohui-virtual-machine:~$ sudo apt-get install -y docker-ce</span><br></pre></td></tr></tbody></table></figure>
<p>4.当前用户加入docker用户组</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">xiaohui@xiaohui-virtual-machine:~$ sudo usermod -aG USER_NAME</span><br><span class="line">#USER_NAME为用户名</span><br></pre></td></tr></tbody></table></figure></body></html>]]></content>
      <tags>
        <tag>Technology Blog</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>
